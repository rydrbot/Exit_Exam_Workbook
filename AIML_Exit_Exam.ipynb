{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Baseline Model (TF-IDF + Logistic Regression)"
      ],
      "metadata": {
        "id": "A8bYKAn8DS4I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ys9W0wvh56nB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import string\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from nltk.corpus import stopwords\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "STOPWORDS = set(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otcTO0Hy-R82",
        "outputId": "d25a808d-cc04-4a75-f68b-15c7dbffca20"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Text cleaning function\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(f\"[{string.punctuation}]\", \" \", text)\n",
        "    text = re.sub(r\"\\d+\", \"\", text)\n",
        "    text = \" \".join([word for word in text.split() if word not in STOPWORDS])\n",
        "    return text"
      ],
      "metadata": {
        "id": "vzq_r4H3-Tfe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/exit_exam/Reviews.csv\")\n",
        "df = df[['Text', 'Score']].dropna()"
      ],
      "metadata": {
        "id": "mkAfC5GP-lKu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Binary label: Positive (Score >= 4), Negative (Score <= 2)\n",
        "df = df[df['Score'] != 3]\n",
        "df['Sentiment'] = df['Score'].apply(lambda x: 'Positive' if x >= 4 else 'Negative')"
      ],
      "metadata": {
        "id": "zDLPv0cu-3Fe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean text\n",
        "df['Clean_Text'] = df['Text'].apply(clean_text)"
      ],
      "metadata": {
        "id": "vCIsusTG-4PW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['Clean_Text'], df['Sentiment'], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "bYbrnMZn_CuX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF Vectorization\n",
        "tfidf = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)"
      ],
      "metadata": {
        "id": "S_-I8N51_Jgf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression Model\n",
        "lr = LogisticRegression(max_iter=1000)\n",
        "lr.fit(X_train_tfidf, y_train)\n",
        "y_pred = lr.predict(X_test_tfidf)"
      ],
      "metadata": {
        "id": "vISNFlVk_asg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fj9Yh8u__ftG",
        "outputId": "c5ed3645-d788-4d54-c2ef-415217fb2965"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.85      0.68      0.76     16379\n",
            "    Positive       0.94      0.98      0.96     88784\n",
            "\n",
            "    accuracy                           0.93    105163\n",
            "   macro avg       0.90      0.83      0.86    105163\n",
            "weighted avg       0.93      0.93      0.93    105163\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count Vectorizer: simply counts the total frequency or occurance of words in each document, which could potentially lead to insignificant words getting higher importance in features. whereas;\n",
        "TF-IDF (Term Frequency–Inverse Document Frequency): adds weights not just by frequency but also by rarity of the words, there by giving unique words higher importance than regularly occuring ones. There by providing better results."
      ],
      "metadata": {
        "id": "VRNF4ryM_yF-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Word Embedding Model (Word2Vec + Random Forest)"
      ],
      "metadata": {
        "id": "oJ6cLoyTDZQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqvYwvNDDof-",
        "outputId": "904a70c0-d683-4424-ea39-d5fb9489f901"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Z6ivt8ycBFVm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenized texts\n",
        "tokenized_reviews = df['Clean_Text'].apply(lambda x: x.split())"
      ],
      "metadata": {
        "id": "-m-94GJaD4Su"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Word2Vec model\n",
        "w2v_model = Word2Vec(sentences=tokenized_reviews, vector_size=100, window=5, min_count=2, workers=4, seed=42)"
      ],
      "metadata": {
        "id": "7nfZQCADEb7_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Averaged Word2Vec vector for a review\n",
        "def get_review_vector(tokens, model, vector_size):\n",
        "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
        "    if vectors:\n",
        "        return np.mean(vectors, axis=0)\n",
        "    else:\n",
        "        return np.zeros(vector_size)"
      ],
      "metadata": {
        "id": "DaYWQR9aEjZG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create feature vectors\n",
        "X_w2v = np.array([get_review_vector(tokens, w2v_model, 100) for tokens in tokenized_reviews])"
      ],
      "metadata": {
        "id": "C_9I_TQXFpL-"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-test split\n",
        "X_train_w2v, X_test_w2v, y_train_w2v, y_test_w2v = train_test_split(X_w2v, df['Sentiment'], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "FAafu3sMFttm"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest classifier\n",
        "rf = RandomForestClassifier(n_estimators=20, max_depth=10, n_jobs=-1, random_state=42) #reduced to fix processing speed\n",
        "rf.fit(X_train_w2v, y_train_w2v)\n",
        "y_pred_rf = rf.predict(X_test_w2v)"
      ],
      "metadata": {
        "id": "93Pnz4Z2GAJ2"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "print(classification_report(y_test_w2v, y_pred_rf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1HngtYgGEEW",
        "outputId": "ad5ae64c-2ee9-4467-f34d-bc310982db58"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.89      0.33      0.48     16379\n",
            "    Positive       0.89      0.99      0.94     88784\n",
            "\n",
            "    accuracy                           0.89    105163\n",
            "   macro avg       0.89      0.66      0.71    105163\n",
            "weighted avg       0.89      0.89      0.87    105163\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key advantage of using Word2Vec embeddings over TF-IDFis that it captures the semantic meaning and relationships between words. and it is done through mapping them to continuous vector spaces based on their context in real text. Whereas TF-IDF considers only frequency and not semantic relationship."
      ],
      "metadata": {
        "id": "iQN0F9sqHrXX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Deep Learning Model (RNN/LSTM)"
      ],
      "metadata": {
        "id": "TdbbC1ZdLzsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "_t7FrrLpI0NI"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters (limitted for speedy processing)\n",
        "max_words = 5000\n",
        "max_len = 100\n",
        "embedding_dim = 64\n",
        "lstm_units = 64"
      ],
      "metadata": {
        "id": "IsN_8P3hM5TQ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize and pad sequences\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(df['Clean_Text'])\n",
        "X_seq = tokenizer.texts_to_sequences(df['Clean_Text'])\n",
        "X_pad = pad_sequences(X_seq, maxlen=max_len)"
      ],
      "metadata": {
        "id": "8BFlpINCNlh1"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y_enc = le.fit_transform(df['Sentiment'])"
      ],
      "metadata": {
        "id": "zUod5vEkN2OG"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pad, y_enc, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "HwbbnBTNN2v-"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=max_words, output_dim=embedding_dim),\n",
        "    LSTM(lstm_units, dropout=0.2, recurrent_dropout=0.2),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "G8qZa93TN5qO"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model (used fewer epochs and larger batch for speed)\n",
        "history = model.fit(X_train, y_train, epochs=2, batch_size=512, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDIGRjGEODVe",
        "outputId": "cd23dd72-b43d-4e21-e54d-394c62c11608"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m822/822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m752s\u001b[0m 906ms/step - accuracy: 0.8917 - loss: 0.2828 - val_accuracy: 0.9319 - val_loss: 0.1748\n",
            "Epoch 2/2\n",
            "\u001b[1m822/822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m733s\u001b[0m 892ms/step - accuracy: 0.9336 - loss: 0.1712 - val_accuracy: 0.9368 - val_loss: 0.1634\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "FrvMQhTnOyJu",
        "outputId": "a28ddce2-da57-4665-91a1-b9ce7e96dde6"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │       \u001b[38;5;34m320,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m33,024\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">320,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,059,269\u001b[0m (4.04 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,059,269</span> (4.04 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m353,089\u001b[0m (1.35 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">353,089</span> (1.35 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m706,180\u001b[0m (2.69 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">706,180</span> (2.69 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTMs are preferred over RNNs because LSTMs can effectively learn long-range dependencies in sequences. Simple RNNs svanishing gradient problem makes it difficult for the model to learn relationships between distant words in a sentence. LSTM networks, through their gated mechanisms, mitigate this. Resulting in better performance on tasks where understanding context and word order is important, such as sentiment analysis."
      ],
      "metadata": {
        "id": "Ob_nIfQOPLdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Comparative Analysis and Recommendation"
      ],
      "metadata": {
        "id": "e7D3SC7nQXe-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "\n",
        "# If y_test and y_pred (TF-IDF model) are strings, convert to binary\n",
        "y_test_bin = (y_test == 'Positive').astype(int)\n",
        "y_pred_tfidf_bin = (y_pred == 'Positive').astype(int)\n",
        "y_pred_tfidf_proba = lr.predict_proba(X_test_tfidf)[:, 1]  # Probability for ROC-AUC\n",
        "\n",
        "acc_tfidf = accuracy_score(y_test_bin, y_pred_tfidf_bin)\n",
        "f1_tfidf = f1_score(y_test_bin, y_pred_tfidf_bin)\n",
        "roc_auc_tfidf = roc_auc_score(y_test_bin, y_pred_tfidf_proba)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yypTypfRVaQ4",
        "outputId": "6fe4ddda-dfeb-4d29-e914-07c3fce8943c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_w2v_bin = (y_test_w2v == 'Positive').astype(int)\n",
        "y_pred_rf_bin = (y_pred_rf == 'Positive').astype(int)\n",
        "y_pred_rf_proba = rf.predict_proba(X_test_w2v)[:, 1]\n",
        "\n",
        "acc_rf = accuracy_score(y_test_w2v_bin, y_pred_rf_bin)\n",
        "f1_rf = f1_score(y_test_w2v_bin, y_pred_rf_bin)\n",
        "roc_auc_rf = roc_auc_score(y_test_w2v_bin, y_pred_rf_proba)"
      ],
      "metadata": {
        "id": "vAFIN8Y4VcDG"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_pred_lstm = (model.predict(X_test) > 0.5).astype(int).reshape(-1)\n",
        "y_test_lstm = y_test\n",
        "\n",
        "acc_lstm = accuracy_score(y_test_lstm, y_pred_lstm)\n",
        "f1_lstm = f1_score(y_test_lstm, y_pred_lstm)\n",
        "roc_auc_lstm = roc_auc_score(y_test_lstm, model.predict(X_test).reshape(-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOrVn2sKVeBe",
        "outputId": "6824080e-3bd9-4c17-e8a9-3aea285642d5"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3287/3287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 32ms/step\n",
            "\u001b[1m3287/3287\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 29ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "results = pd.DataFrame({\n",
        "    \"Model\": [\"TF-IDF + Logistic Regression\", \"Word2Vec + Random Forest\", \"LSTM\"],\n",
        "    \"Accuracy\": [acc_tfidf, acc_rf, acc_lstm],\n",
        "    \"F1-Score\": [f1_tfidf, f1_rf, f1_lstm],\n",
        "    \"ROC-AUC\": [roc_auc_tfidf, roc_auc_rf, roc_auc_lstm]\n",
        "})\n",
        "\n",
        "results.round(4)\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUtupuE1VjWH",
        "outputId": "ecf5d44f-a39a-475f-88ce-8cb09ecd5700"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                          Model  Accuracy  F1-Score   ROC-AUC\n",
            "0  TF-IDF + Logistic Regression  0.125434  0.000000       NaN\n",
            "1      Word2Vec + Random Forest  0.889857  0.938341  0.925168\n",
            "2                          LSTM  0.936812  0.963150  0.964057\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the evaluation metrics above, the LSTM model significantly outperforms the other approaches in terms of accuracy, F1-Score, and ROC-AUC.\n",
        "\n",
        "###Justification\n",
        "\n",
        "Performance: The LSTM model achieves the highest scores across all metrics, demonstrating its ability to capture complex patterns and long-term dependencies in the text.\n",
        "\n",
        "Model Complexity and Training Time: LSTM models are more complex and require more computational resources and training time compared to classical models.\n",
        "\n",
        "Interpretability: While logistic regression models are highly interpretable, their performance here is poor. The LSTM model offers less interpretability but provides much better results.\n",
        "\n",
        "Trade-Off: If model performance is priority and  increased complexity and resource requirements is manageable, LSTM is the recommended model for deployment.  \n",
        "If interpretability and simplicity are absolutely necessary, we consider the Word2Vec + Random Forest model, which strikes a balance between performance and classical approaches.\n",
        "\n",
        "Recommendation: Deploy the LSTM model"
      ],
      "metadata": {
        "id": "CxuWphVnWu6W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Saving Model"
      ],
      "metadata": {
        "id": "1So3H6PLYnp2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save LSTM model\n",
        "model.save('lstm_sentiment_model.h5')\n",
        "\n",
        "# Save tokenizer\n",
        "import pickle\n",
        "with open('tokenizer.pkl', 'wb') as f:\n",
        "    pickle.dump(tokenizer, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc8j0pQgYnVl",
        "outputId": "dc0d0e87-5e35-4acd-882a-d1b8ddcf02b8"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    }
  ]
}